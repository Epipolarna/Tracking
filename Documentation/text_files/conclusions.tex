


\subsection{Shadow suppression}
One of the reasons that the performance is drastically lower for the last sequence is that it contains not only shadows, but specular reflections as well and this is something the HSV model does not take into account. There are also problems with persons walking in front of only slightly darker walls of the same hue, causing false positives. In the sequences used for evaluation $\tau_S$ is set to one, which means that the condition in equation \eqref{eq:S} is always fulfilled. One reason that this yields better performance might be that there is some secularity involved in the shadowing as well as the fact that false positives from the shadow suppression might split foreground regions apart. This might cause the segmentation to yield false positives, drastically lowering MOTA performance.

\subsubsection{Possible improvements}
The shadow suppression algorithm also has great problems handling varying illumination in the scene. One way to solve this could be to somehow make the parameter settings depend on the overall illumination of the scene. 

\subsection{Foreground noise removal and segmentation}
The foreground segmentation performance depends highly on the parameter settings and what is deemed as good performance in terms of noise removal and segmentation depends highly on both the input characteristics as well as what the expected segmentation output is. The implementation used to achieve the results in section \ref{sec:results}  is the one  described in section \ref{sec:foreground_segmentation}. In this implementation the background model generates significantly more false positives than negatives, while at the same time the identification module is good at handling false negatives and not good at all with false positives. 

\subsubsection{Possible improvements}
The implementation of the foreground segmentation described in the previous paragraph can, however be rather slow if there are a lot of objects to track. To enable the segmentation to run in real-time, one might want to choose one of the faster implementations, where noise removal is handled by some erode/dilate sequences together with removal of objects that are e.g. not convex enough. With an other background model and/or identification modules one of these other algorithms might even yield better performance in terms of MOTA and MOTP.

\subsection{Identification}


\subsubsection{Possible improvements}
When objects are lost for too long and without any velocity, which would otherwise indicate that the object might temporary be behind a hinder, it should probably be removed in order ot compensate for ghost objects let through by the background modelling and the foreground segmentation. Another indication for removal could be when the uncertainty grows much larger than the entire frame.

Objects could also be forced to change width/height very slowly, both when moving freely and when entering/exiting parent objects. This was partly implemented but was discarded due to lack of time.

\subsection{Kalman Predictor}
The Kalman predictor did overall work well. The state-space model including only position and velocity worked good enough for its purpose. It did however face difficulties with sudden objects appearing then suddenly disappearing, yielding predictions with unstable velocity due to few measurements. Tweaking of parameters
where made but still there was problems that could only be solved by denying velocity predictions until enough information was gathered. This did however also cause problem for briefly appearing objects that did not get any velocity estimation and thus did not move when vision was lost. These got stock in the middle of the sequence causing false positive errors for the evaluation.

\subsubsection{Possible improvements}
It is always possible to use more advance state-space models including for instance acceleration that could possibly lead to improvements in the predictors performance. It is however not certain that it will. Some test where carried out using acceleration that did not show any significant improvement. The parameters involved in the predictor can as well be subject to hours of tweaking and tuning, and thereby possibly improved, but our time budget could not allow for such indulgence. 















