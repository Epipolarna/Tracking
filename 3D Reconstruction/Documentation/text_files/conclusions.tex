In general this project needed much better routines for testing and verification of indvidiual modules than the previous project, mainly due to far longer computational times involved.

\subsection{Correspondence Extractor}
It is fairly important to do the correspondence extraction well. There are a couple of parameters that need to be tuned properly for every sequence. The features need be evenly distributed in the image the get enough information. It is for instance not good to have all features in a plane or many feature close to each other. This is solved with a minimum distance allowed between features. It is also important to look for features of the right size. This depends on resolution and image structure. To keep the number of features low and the quality high helps the program run faster. 

\subsubsection{Possible improvements}
Automatic parameter detection based on image analysis in some way would make the program more user friendly. At the moment it requires an experienced user. 

\subsection{Pose Estimator}
The pose estimator is very sensitive to the quality of the correspondences. It does not handle outliers or points on a plane very well. This corrupts the estimation completely since it cannot provide even rough estimates to the bundle adjustment optimization. However, as long as the outliers are removed and the points are spread out in more than two dimensions it works very well. 

Deducting which 3D-points were seen in the previous image it was possible to run PnP on the known 3D-points in order to improve the pose of the new camera significantly. Using this result it was possible to remove most problematic outliers by triangulating the new points and to threshold them according to their re-projection error. This both improved the result and increased the speed of the computations in the BA step as it was given a better initial estimate.

\subsubsection{Possible improvements}
If something about the camera trajectory is known one could possibly constrain the pose estimation and make it more robust.
Another possible improvement would be to find chains of corresponding points though out the image sequence which then should correspond to the same 3D-point. 
\newpage

Using as long chains as possible while still always have at least a minimum of image points in each image they could be cross-validated for each image and the worst points removed from the chains, splitting these, and resulting in possibly very high-quality estimates of trajectories of 3D-points captured in the image sequence. These chains could then be used in the pipeline resulting in a very sparse 3D-model with possibly very high camera pose estimation accuracy. The next step would then be to triangulate most other image points using these "known" cameras and building up a dense 3D-model. Additional verifications, validations and re-estimations of the camera-poses might be done in order to ensure that the estimated cameras poses are indeed very accurate. The speed up from this process could be very large, as well as the quality of the model perhaps!

\subsection{Non-linear Optimizer}
The non-linear optimization implementation performs well and no significant problems related to neither the pose representation, nor the representation of points or the visibility function were struck. The hardest part was to figure out how to convert all the data to fit the API, but once that was figured out, the implementation was very straight-forward, and the bundle adjustment part was not much harder to implement than the Gold Standard or PnP parts.

\subsubsection{Possible improvements}
The improvement that would yield the largest performance increase in the bundle adjustment would be making use of the lack of independence between views and drastically lower the computational load. The original thought was to use the sparseLM API \cite{sparseLM}. Unfortunately, due to lack of time, this was never implemented as it would require the representation of the visibility function to be remade completely. 

A second significant improvement would be to make use of the LAPACK API, that was highly recommended for use in combination with levmar, and said to speed things up significantly. It was, however, rather complicated and time consuming to set up, and these are the reasons it is not used in this implementation.

\subsection{3D Visualization}
Implementing this part of the system in OpenGL was perhaps not the wisest decision, as the amount of work and difficulty to debug OpenGL calls made progress rather slow.

It did however make it easy to implement project-specific functions into the visualizer without having to learn yet another API.

\subsubsection{Possible improvements}
It should be possible to color the points according to the image data they are extracted from. If more points where obtained it should be possible to draw them only as colored dots in space.

Further one might create a mesh between the detected points, to generate a full 3D-Model. It should then also be possible to texture it using data from the images to create a complete 3D representation of the original physical object.

Another improvement would be to add runtime settings to many of the options that are currently set in the source code, as recompiling the program every time the scale of the objects need to change is somewhat clumsy.